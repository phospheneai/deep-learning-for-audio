{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWOirozFtUiS",
        "outputId": "918922d1-7ec1-47a9-a12f-c631c463c9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting soundata\n",
            "  Downloading soundata-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from soundata) (0.10.2.post1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from soundata) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from soundata) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from soundata) (4.67.1)\n",
            "Collecting jams>=0.3.4 (from soundata)\n",
            "  Downloading jams-0.3.4.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py7zr>=0.16.0 (from soundata)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting sortedcontainers>=2.0.0 (from jams>=0.3.4->soundata)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from jams>=0.3.4->soundata) (4.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jams>=0.3.4->soundata) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from jams>=0.3.4->soundata) (4.4.2)\n",
            "Collecting mir_eval>=0.5 (from jams>=0.3.4->soundata)\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->soundata) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->soundata) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->soundata) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->soundata) (2024.2)\n",
            "Collecting texttable (from py7zr>=0.16.0->soundata)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr>=0.16.0->soundata) (5.9.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->soundata) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->soundata) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->soundata) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->soundata) (0.22.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa>=0.10.0->soundata) (24.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval>=0.5->jams>=0.3.4->soundata) (1.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.10.0->soundata) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.10.0->soundata) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.10.0->soundata) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.10.0->soundata) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.10.0->soundata) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10.0->soundata) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (2024.12.14)\n",
            "Downloading soundata-1.0.1-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.0/162.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: jams, mir_eval\n",
            "  Building wheel for jams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jams: filename=jams-0.3.4-py3-none-any.whl size=64901 sha256=f3f7c3ded417de7fd4512ecd30419e1bd49763b2128af026ddddb5deb8d0aeb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/9a/f7/fb386b6bc5a75a3ef198a50e98b221e94a381472332b65cf24\n",
            "  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100699 sha256=464cba038f1140ec96db279e6d5179a1ccc7974daf19aa01b3ec7fcea25ee245\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n",
            "Successfully built jams mir_eval\n",
            "Installing collected packages: texttable, sortedcontainers, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr, mir_eval, jams, soundata\n",
            "Successfully installed brotli-1.1.0 inflate64-1.0.1 jams-0.3.4 mir_eval-0.7 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.3 pycryptodomex-3.21.0 pyppmd-1.1.1 pyzstd-0.16.2 sortedcontainers-2.4.0 soundata-1.0.1 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install soundata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchaudio\n",
        "import librosa\n",
        "import soundata\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "2AgIgIuBtWVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "BlaUqztuuxQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = soundata.initialize('urbansound8k', data_home='/content/data')\n",
        "dataset.download()  # download the dataset\n",
        "dataset.validate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tRjob7-tbec",
        "outputId": "12baefaa-d0f0-4d81-d103-fa5b60b4088c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5.61GB [08:08, 12.3MB/s]                            \n",
            "1.15MB [00:01, 672kB/s]                           \n",
            "100%|██████████| 1/1 [00:00<00:00, 397.19it/s]\n",
            "100%|██████████| 8732/8732 [00:52<00:00, 167.18it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'metadata': {}, 'clips': {}}, {'metadata': {}, 'clips': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vvJLzqtP2J7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(Dataset):\n",
        "  def __init__(self, metadata_file, audio_dir, transform=None, max_length = 128):\n",
        "    self.metadata = pd.read_csv(metadata_file)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.transform = transform\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.label_encoder = LabelEncoder()\n",
        "    self.metadata['encoded_label'] = self.label_encoder.fit_transform(self.metadata['class'])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.metadata)\n",
        "\n",
        "  def pad_or_truncate(self, mel_spec):\n",
        "    if mel_spec.shape[1] > self.max_length:\n",
        "      mel_spec = mel_spec[:, :self.max_length]\n",
        "\n",
        "    else:\n",
        "      pad_width = self.max_length - mel_spec.shape[1]\n",
        "      mel_spec = np.pad(mel_spec, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    return mel_spec\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.metadata.iloc[idx]\n",
        "    audio_path = os.path.join(self.audio_dir, f\"fold{str(row['fold'])}\", row['slice_file_name'])\n",
        "    label = row['encoded_label']\n",
        "\n",
        "    try:\n",
        "      signal, sr = librosa.load(audio_path, sr=22050)\n",
        "      mel_spec = librosa.feature.melspectrogram(\n",
        "          y=signal,\n",
        "          sr=sr,\n",
        "          n_mels=128,\n",
        "          hop_length=512\n",
        "        )\n",
        "      mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "      mel_spec_db = self.pad_or_truncate(mel_spec_db)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing {audio_path}: {e}\")\n",
        "      return None, None\n",
        "\n",
        "    if self.transform:\n",
        "      mel_spec_db = self.transform(mel_spec_db)\n",
        "    mel_spec_db = torch.tensor(mel_spec_db, dtype=torch.float32).unsqueeze(0)\n",
        "    return mel_spec_db, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "Z3bXqFaZt9A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_path = '/content/data/metadata/UrbanSound8K.csv'\n",
        "audio_path = '/content/data/audio'"
      ],
      "metadata": {
        "id": "uYdHQD9Stg1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = UrbanSoundDataset(metadata_path, audio_path)\n",
        "train_size = int(0.8 * len(dataset))  # 80% of the dataset for training\n",
        "val_size = len(dataset) - train_size  # Remaining 20% for validation\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "XeJUmPj4yNUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "for features, labels in train_dataloader:\n",
        "    print(f\"Feature batch shape: {features.shape}\")\n",
        "    print(f\"Label batch shape: {labels.shape}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4lVaT4zyZSR",
        "outputId": "76c943ee-a905-42d6-dd0c-4cce849c7fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 128, 128])\n",
            "Label batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AudioClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Input: (1, 128, 128)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: (64, 64, 64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Halves each dimension\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc1 = nn.Linear(64 * 32 * 32, 256)  # Adjust dimensions based on input size\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Conv -> BN -> ReLU -> Pool\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)  # Final output (logits)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tZtmPrtlyfLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18AudioClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18AudioClassifier, self).__init__()\n",
        "\n",
        "        # Load ResNet-18 without pretrained weights\n",
        "        self.resnet18 = models.resnet18(pretrained=False)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1 channel input (grayscale)\n",
        "        self.resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # Modify the fully connected layer to match the number of output classes\n",
        "        self.resnet18.fc = nn.Linear(self.resnet18.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)"
      ],
      "metadata": {
        "id": "ruSXGMp9h2XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(dataset.label_encoder.classes_)\n",
        "model = ResNet18AudioClassifier(num_classes).to(device)\n",
        "\n",
        "print(model(features.to(device)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZtyz0j1Reg",
        "outputId": "660f6dd9-d66b-42d5-dae1-e0d39179042f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7DKGY5UV1TeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15"
      ],
      "metadata": {
        "id": "an8VIfKv14CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training phase with TQDM for batches\n",
        "    with tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as batch_tqdm:\n",
        "        for features, labels in batch_tqdm:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = model(features)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Optimize model parameters\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "            # Update batch progress bar\n",
        "            batch_tqdm.set_postfix(loss=loss.item(), accuracy=correct_predictions/total_predictions)\n",
        "\n",
        "    # Calculate training statistics\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions * 100\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for features, labels in val_dataloader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(features)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    # Calculate validation accuracy and loss\n",
        "    val_loss = val_loss / len(val_dataloader)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions * 100\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNzN8bC22Y4C",
        "outputId": "2c6df7c5-2898-4cd9-fdd4-11e820c9c243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/15:   0%|          | 0/219 [00:00<?, ?batch/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
            "  warnings.warn(\n",
            "Epoch 1/15:  19%|█▊        | 41/219 [00:32<02:46,  1.07batch/s, accuracy=0.327, loss=1.59]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
            "  warnings.warn(\n",
            "Epoch 1/15:  30%|███       | 66/219 [00:50<01:47,  1.42batch/s, accuracy=0.384, loss=1.3]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
            "  warnings.warn(\n",
            "Epoch 1/15: 100%|██████████| 219/219 [02:46<00:00,  1.32batch/s, accuracy=0.553, loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 1.2737, Accuracy: 55.29%, Time: 166.18s\n",
            "Validation Loss: 1.0881, Validation Accuracy: 63.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 219/219 [02:40<00:00,  1.37batch/s, accuracy=0.769, loss=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/15], Loss: 0.6879, Accuracy: 76.92%, Time: 160.28s\n",
            "Validation Loss: 1.2664, Validation Accuracy: 62.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 219/219 [02:40<00:00,  1.36batch/s, accuracy=0.827, loss=0.797]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/15], Loss: 0.5041, Accuracy: 82.69%, Time: 160.78s\n",
            "Validation Loss: 1.4200, Validation Accuracy: 61.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 219/219 [02:32<00:00,  1.43batch/s, accuracy=0.879, loss=0.324]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/15], Loss: 0.3729, Accuracy: 87.89%, Time: 152.88s\n",
            "Validation Loss: 0.9498, Validation Accuracy: 74.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 219/219 [02:33<00:00,  1.43batch/s, accuracy=0.905, loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/15], Loss: 0.3024, Accuracy: 90.51%, Time: 153.29s\n",
            "Validation Loss: 0.5584, Validation Accuracy: 81.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 219/219 [02:32<00:00,  1.44batch/s, accuracy=0.92, loss=0.197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/15], Loss: 0.2490, Accuracy: 92.04%, Time: 152.11s\n",
            "Validation Loss: 0.4950, Validation Accuracy: 84.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|██████████| 219/219 [02:32<00:00,  1.44batch/s, accuracy=0.939, loss=0.461]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/15], Loss: 0.1908, Accuracy: 93.86%, Time: 152.19s\n",
            "Validation Loss: 0.5066, Validation Accuracy: 84.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|██████████| 219/219 [02:34<00:00,  1.42batch/s, accuracy=0.943, loss=0.0817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/15], Loss: 0.1601, Accuracy: 94.29%, Time: 154.08s\n",
            "Validation Loss: 0.9699, Validation Accuracy: 74.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|██████████| 219/219 [02:33<00:00,  1.43batch/s, accuracy=0.948, loss=0.356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/15], Loss: 0.1436, Accuracy: 94.80%, Time: 153.51s\n",
            "Validation Loss: 0.3541, Validation Accuracy: 88.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|██████████| 219/219 [02:33<00:00,  1.42batch/s, accuracy=0.954, loss=0.0226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/15], Loss: 0.1200, Accuracy: 95.45%, Time: 153.72s\n",
            "Validation Loss: 0.4482, Validation Accuracy: 87.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|██████████| 219/219 [02:35<00:00,  1.41batch/s, accuracy=0.97, loss=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/15], Loss: 0.0866, Accuracy: 96.95%, Time: 155.06s\n",
            "Validation Loss: 0.5398, Validation Accuracy: 86.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|██████████| 219/219 [02:31<00:00,  1.44batch/s, accuracy=0.96, loss=0.359]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/15], Loss: 0.1048, Accuracy: 96.03%, Time: 151.58s\n",
            "Validation Loss: 0.9068, Validation Accuracy: 75.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|██████████| 219/219 [02:33<00:00,  1.43batch/s, accuracy=0.966, loss=0.0222]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/15], Loss: 0.0954, Accuracy: 96.61%, Time: 153.02s\n",
            "Validation Loss: 0.4506, Validation Accuracy: 86.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|██████████| 219/219 [02:33<00:00,  1.43batch/s, accuracy=0.977, loss=0.0703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/15], Loss: 0.0664, Accuracy: 97.67%, Time: 153.13s\n",
            "Validation Loss: 0.5176, Validation Accuracy: 87.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|██████████| 219/219 [02:31<00:00,  1.45batch/s, accuracy=0.971, loss=0.034]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/15], Loss: 0.0886, Accuracy: 97.05%, Time: 151.30s\n",
            "Validation Loss: 0.5175, Validation Accuracy: 86.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOWmzmzj2gre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}